"""
æ‰§è¡Œç»“æœç›‘æ§ç»„ä»¶ (Component 2/6)
èŒè´£ï¼šåˆ†ææ‰§è¡Œç»“æœï¼Œæ£€æµ‹å´©æºƒã€ä¿å­˜æœ‰è¶£çš„æµ‹è¯•ç”¨ä¾‹

æ›´æ–°ç‰ˆï¼ˆè¦†ç›–ç‡å¼•å¯¼ï¼‰ï¼šåŸºäºè¦†ç›–ç‡å¢é‡ç­›é€‰æœ‰è¶£çš„è¾“å…¥
"""

import json
import hashlib
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional


class ExecutionMonitor:
    """
    æ‰§è¡Œç»“æœç›‘æ§å™¨
    è®°å½•å´©æºƒã€ç»Ÿè®¡æ•°æ®ã€è¿½è¸ªè¦†ç›–ç‡
    """
    
    def __init__(self, output_dir: str, use_coverage: bool = False):
        """
        åˆå§‹åŒ–ç›‘æ§å™¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
            use_coverage: æ˜¯å¦å¯ç”¨è¦†ç›–ç‡å¼•å¯¼
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.use_coverage = use_coverage
        
        # å­ç›®å½•
        self.crashes_dir = self.output_dir / 'crashes'
        self.queue_dir = self.output_dir / 'queue'
        self.crashes_dir.mkdir(exist_ok=True)
        self.queue_dir.mkdir(exist_ok=True)
        
        # å…¨å±€è¦†ç›–ç‡ bitmapï¼ˆç´¯ç§¯æ‰€æœ‰å‘ç°çš„è¾¹ï¼‰
        self.global_coverage: Optional[bytearray] = None
        if use_coverage:
            # é»˜è®¤ 64KB bitmap
            self.global_coverage = bytearray(65536)
        
        # ç»Ÿè®¡æ•°æ®
        self.stats = {
            'total_execs': 0,
            'total_crashes': 0,
            'unique_crashes': set(),
            'start_time': datetime.now().isoformat(),
            'interesting_inputs': 0,
            'total_coverage_bits': 0
        }
        
        mode = "coverage-guided" if use_coverage else "blind"
        print(f"[Monitor] Initialized ({mode}). Output dir: {self.output_dir}")
    
    def process_execution(self, input_data: bytes, exec_result: Dict) -> bool:
        """
        å¤„ç†ä¸€æ¬¡æ‰§è¡Œç»“æœ
        
        Args:
            input_data: è¾“å…¥æ•°æ®
            exec_result: æ‰§è¡Œç»“æœï¼ˆæ¥è‡ª executorï¼‰
        
        Returns:
            æ˜¯å¦æ˜¯æœ‰è¶£çš„æ‰§è¡Œï¼ˆæ–°è¦†ç›–ç‡ã€å´©æºƒæˆ–å…¶ä»–å¼‚å¸¸ï¼‰
        """
        self.stats['total_execs'] += 1
        
        is_interesting = False
        
        # æ£€æµ‹å´©æºƒ
        if exec_result.get('crashed', False):
            self._handle_crash(input_data, exec_result)
            is_interesting = True
        
        # æ£€æµ‹è¶…æ—¶
        if exec_result.get('timeout', False):
            self._save_interesting(input_data, 'timeout')
            is_interesting = True
        
        # æ£€æµ‹æ–°è¦†ç›–ç‡
        if self.use_coverage and exec_result.get('coverage'):
            has_new_coverage = self._update_coverage(exec_result['coverage'])
            if has_new_coverage:
                self._save_interesting(input_data, 'new_coverage')
                is_interesting = True
        
        return is_interesting
    
    def _update_coverage(self, coverage_bitmap: bytes) -> bool:
        """
        æ›´æ–°å…¨å±€è¦†ç›–ç‡
        
        Args:
            coverage_bitmap: æœ¬æ¬¡æ‰§è¡Œçš„è¦†ç›–ç‡
        
        Returns:
            æ˜¯å¦å‘ç°äº†æ–°çš„è¦†ç›–
        """
        if not self.global_coverage:
            return False
        
        has_new = False
        for i, byte_val in enumerate(coverage_bitmap):
            if byte_val != 0:
                # å¦‚æœå…¨å±€ bitmap ä¸­è¿™ä¸ªä½ç½®ä¹‹å‰æ˜¯0ï¼Œç°åœ¨å˜æˆé0ï¼Œè¯´æ˜æ˜¯æ–°è¾¹
                if self.global_coverage[i] == 0:
                    has_new = True
                # æ›´æ–°å…¨å±€ bitmapï¼ˆä½¿ç”¨æŒ‰ä½æˆ–ï¼‰
                self.global_coverage[i] |= byte_val
        
        if has_new:
            # é‡æ–°è®¡ç®—æ€»è¦†ç›–ä½æ•°
            self.stats['total_coverage_bits'] = sum(
                bin(b).count('1') for b in self.global_coverage
            )
        
        return has_new
    
    def _handle_crash(self, input_data: bytes, exec_result: Dict):
        """å¤„ç†å´©æºƒ"""
        # è®¡ç®—å´©æºƒçš„å“ˆå¸Œï¼ˆç”¨äºå»é‡ï¼‰
        stderr = exec_result.get('stderr', b'')
        if isinstance(stderr, str):
            stderr = stderr.encode()
        
        crash_hash = hashlib.md5(stderr).hexdigest()[:8]
        
        # æ£€æµ‹æ˜¯å¦æ˜¯æ–°çš„å´©æºƒ
        if crash_hash not in self.stats['unique_crashes']:
            self.stats['unique_crashes'].add(crash_hash)
            self.stats['total_crashes'] = len(self.stats['unique_crashes'])
            
            # ä¿å­˜å´©æºƒè¾“å…¥
            crash_id = self.stats['total_execs']
            filename = f"crash_{crash_id}_{crash_hash}"
            crash_file = self.crashes_dir / filename
            
            crash_file.write_bytes(input_data)
            
            # ä¿å­˜å´©æºƒä¿¡æ¯
            info_file = self.crashes_dir / f"{filename}.json"
            info = {
                'exec_id': crash_id,
                'hash': crash_hash,
                'return_code': exec_result.get('return_code'),
                'exec_time': exec_result.get('exec_time'),
                'stderr': stderr.decode('utf-8', errors='ignore')[:500]
            }
            info_file.write_text(json.dumps(info, indent=2))
            
            print(f"[Monitor] ğŸ”´ New crash found! ({self.stats['total_crashes']} unique)")
    
    def _save_interesting(self, input_data: bytes, reason: str):
        """ä¿å­˜æœ‰è¶£çš„è¾“å…¥ï¼ˆéå´©æºƒä½†å€¼å¾—å…³æ³¨ï¼‰"""
        self.stats['interesting_inputs'] += 1
        
        filename = f"{reason}_{self.stats['total_execs']}"
        queue_file = self.queue_dir / filename
        queue_file.write_bytes(input_data)
    
    def get_current_stats(self) -> Dict:
        """è·å–å½“å‰ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'total_execs': self.stats['total_execs'],
            'total_crashes': self.stats['total_crashes'],
            'interesting_inputs': self.stats['interesting_inputs'],
            'start_time': self.stats['start_time']
        }
    
    def save_stats_to_file(self):
        """ä¿å­˜ç»Ÿè®¡ä¿¡æ¯åˆ°æ–‡ä»¶"""
        stats_file = self.output_dir / 'stats.json'
        
        # è½¬æ¢ set ä¸º list ä»¥ä¾¿ JSON åºåˆ—åŒ–
        exportable_stats = {
            'total_execs': self.stats['total_execs'],
            'total_crashes': self.stats['total_crashes'],
            'unique_crashes': list(self.stats['unique_crashes']),
            'start_time': self.stats['start_time'],
            'end_time': datetime.now().isoformat(),
            'interesting_inputs': self.stats['interesting_inputs']
        }
        
        stats_file.write_text(json.dumps(exportable_stats, indent=2))
        print(f"[Monitor] Stats saved to {stats_file}")


# ========== æµ‹è¯•ä»£ç  ==========
if __name__ == '__main__':
    import tempfile
    import shutil
    
    # åˆ›å»ºä¸´æ—¶è¾“å‡ºç›®å½•
    temp_dir = tempfile.mkdtemp(prefix='monitor_test_')
    
    try:
        monitor = ExecutionMonitor(temp_dir)
        
        # æ¨¡æ‹Ÿæ­£å¸¸æ‰§è¡Œ
        normal_result = {
            'return_code': 0,
            'exec_time': 0.01,
            'crashed': False,
            'timeout': False
        }
        monitor.process_execution(b'normal input', normal_result)
        
        # æ¨¡æ‹Ÿå´©æºƒ
        crash_result = {
            'return_code': -11,
            'exec_time': 0.02,
            'crashed': True,
            'stderr': b'Segmentation fault'
        }
        monitor.process_execution(b'crash input', crash_result)
        
        # æ‰“å°ç»Ÿè®¡
        stats = monitor.get_current_stats()
        print(f"\nStats: {stats}")
        
        # ä¿å­˜ç»Ÿè®¡
        monitor.save_stats_to_file()
        
    finally:
        # æ¸…ç†
        shutil.rmtree(temp_dir)
        print(f"Cleaned up {temp_dir}")
